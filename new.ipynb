{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1: Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\renee\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.5.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\renee\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.20.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\renee\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\renee\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\renee\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\renee\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\renee\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\renee\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\renee\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\renee\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\renee\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torchvision) (2.1.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\renee\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\renee\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\renee\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch-geometric==2.3.0 in c:\\users\\renee\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.3.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\renee\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch-geometric==2.3.0) (4.67.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\renee\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch-geometric==2.3.0) (2.1.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\renee\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch-geometric==2.3.0) (1.14.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\renee\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch-geometric==2.3.0) (3.1.4)\n",
      "Requirement already satisfied: requests in c:\\users\\renee\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch-geometric==2.3.0) (2.32.3)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\renee\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch-geometric==2.3.0) (3.2.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\renee\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch-geometric==2.3.0) (1.5.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\renee\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch-geometric==2.3.0) (6.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\renee\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->torch-geometric==2.3.0) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\renee\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->torch-geometric==2.3.0) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\renee\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->torch-geometric==2.3.0) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\renee\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->torch-geometric==2.3.0) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\renee\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests->torch-geometric==2.3.0) (2024.8.30)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\renee\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn->torch-geometric==2.3.0) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\renee\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn->torch-geometric==2.3.0) (3.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\renee\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tqdm->torch-geometric==2.3.0) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\renee\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\renee\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\renee\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.1.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\renee\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\renee\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\renee\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\renee\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\renee\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\renee\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\renee\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\renee\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\renee\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n",
      "ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'import torch; print(torch.__version__)).html'\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\renee\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio\n",
    "!pip install torch-geometric==2.3.0\n",
    "!pip install pandas numpy scikit-learn\n",
    "!pip install torch-scatter -f https://data.pyg.org/whl/torch-$(python -c \"import torch; print(torch.__version__)\").html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2: Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import degree\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_scatter import scatter_softmax\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import random\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 3: Setting Device and Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# For reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if device.type == 'cuda':\n",
    "    torch.cuda.manual_seed_all(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 4: Load and Preprocess the MovieLens Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 610\n",
      "Number of items: 9724\n",
      "Number of total nodes: 10334\n",
      "Number of interactions: 100836\n"
     ]
    }
   ],
   "source": [
    "# Ensure the dataset is in the working directory: 'ml-latest-small/ratings.csv' and 'movies.csv'\n",
    "ratings = pd.read_csv('ml-latest-small/ratings.csv')\n",
    "movies = pd.read_csv('ml-latest-small/movies.csv')\n",
    "\n",
    "# Filter out any rows with missing userIds (shouldn't happen, but just in case)\n",
    "ratings = ratings[ratings['userId'].notna()]\n",
    "\n",
    "# Map user and movie IDs to consecutive integers\n",
    "user_id_mapping = {id: idx for idx, id in enumerate(ratings['userId'].unique())}\n",
    "item_id_mapping = {id: idx for idx, id in enumerate(ratings['movieId'].unique())}\n",
    "\n",
    "ratings['userId'] = ratings['userId'].map(user_id_mapping)\n",
    "ratings['movieId'] = ratings['movieId'].map(item_id_mapping)\n",
    "\n",
    "num_users = ratings['userId'].nunique()\n",
    "num_items = ratings['movieId'].nunique()\n",
    "num_nodes = num_users + num_items\n",
    "\n",
    "print(\"Number of users:\", num_users)\n",
    "print(\"Number of items:\", num_items)\n",
    "print(\"Number of total nodes:\", num_nodes)\n",
    "print(\"Number of interactions:\", len(ratings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 5: Create Graph Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create edge index for the entire dataset\n",
    "# Users are [0, num_users-1], Items are [num_users, num_users+num_items-1]\n",
    "user_nodes = ratings['userId'].to_numpy()\n",
    "item_nodes = ratings['movieId'].to_numpy() + num_users\n",
    "\n",
    "edge_index = np.vstack((user_nodes, item_nodes))\n",
    "edge_index = torch.tensor(edge_index, dtype=torch.long)\n",
    "\n",
    "# Edge attributes are the ratings\n",
    "edge_attr = torch.tensor(ratings['rating'].to_numpy(), dtype=torch.float32)\n",
    "\n",
    "# Feature matrix: we can start with a simple identity or zero embeddings, as LightGCN learns embeddings directly\n",
    "# We'll rely solely on the learned embeddings from the model\n",
    "data = Data(edge_index=edge_index, num_nodes=num_nodes)\n",
    "\n",
    "# Move to device\n",
    "data = data.to(device)\n",
    "edge_attr = edge_attr.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 6: Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(ratings, test_size=0.2, random_state=42)\n",
    "\n",
    "train_user = torch.tensor(train_data['userId'].values, dtype=torch.long, device=device)\n",
    "train_item = torch.tensor(train_data['movieId'].values + num_users, dtype=torch.long, device=device)\n",
    "train_rating = torch.tensor(train_data['rating'].values, dtype=torch.float32, device=device)\n",
    "\n",
    "test_user = torch.tensor(test_data['userId'].values, dtype=torch.long, device=device)\n",
    "test_item = torch.tensor(test_data['movieId'].values + num_users, dtype=torch.long, device=device)\n",
    "test_rating = torch.tensor(test_data['rating'].values, dtype=torch.float32, device=device)\n",
    "\n",
    "# For Recall@K calculation, we will need the test edges separately\n",
    "test_edge_index = torch.stack([test_user, test_item], dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 7: Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(true_ratings, pred_ratings):\n",
    "    return np.sqrt(mean_squared_error(true_ratings, pred_ratings))\n",
    "\n",
    "def recall_at_k(model, k=10):\n",
    "    \"\"\"\n",
    "    Compute Recall@K on the test set:\n",
    "    - We consider all items and see if the items the user actually interacted with (in test set)\n",
    "      appear in the top K recommendations for that user.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Get embeddings\n",
    "        embeddings = model.get_embedding(data.edge_index)\n",
    "        user_emb = embeddings[:num_users]\n",
    "        item_emb = embeddings[num_users:num_users+num_items]\n",
    "\n",
    "        # Compute scores [num_users x num_items]\n",
    "        scores = user_emb @ item_emb.T\n",
    "\n",
    "        # Get top-k items for each user\n",
    "        _, top_k_items = torch.topk(scores, k, dim=1)\n",
    "\n",
    "        # Convert test set into a dict: user -> set of test items\n",
    "        test_user_items = {}\n",
    "        for u, i, r in zip(test_data['userId'], test_data['movieId'], test_data['rating']):\n",
    "            # Only consider items where user interacted positively (rating > 0)\n",
    "            # In MovieLens all ratings > 0 by definition, but we keep the check for generality\n",
    "            if u not in test_user_items:\n",
    "                test_user_items[u] = set()\n",
    "            test_user_items[u].add(i)\n",
    "\n",
    "        recalls = []\n",
    "        for u in range(num_users):\n",
    "            if u in test_user_items and len(test_user_items[u]) > 0:\n",
    "                recommended = set((top_k_items[u].cpu().numpy()))\n",
    "                relevant = test_user_items[u]\n",
    "                hit_count = len(recommended & relevant)\n",
    "                recall_u = hit_count / len(relevant)\n",
    "                recalls.append(recall_u)\n",
    "            else:\n",
    "                # If a user has no test items, skip them or consider recall as 0\n",
    "                # Usually, we consider only users with test interactions\n",
    "                pass\n",
    "\n",
    "        if len(recalls) == 0:\n",
    "            return 0.0\n",
    "        return float(np.mean(recalls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 8: LightGCN Model (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightGCNConv(MessagePassing):\n",
    "    def __init__(self):\n",
    "        super().__init__(aggr='add')\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        row, col = edge_index\n",
    "        deg = degree(col, x.size(0), dtype=x.dtype)\n",
    "        deg_inv_sqrt = (deg + 1e-7).pow(-0.5) \n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "        return self.propagate(edge_index, x=x, norm=norm)\n",
    "\n",
    "    def message(self, x_j, norm):\n",
    "        return norm.view(-1, 1) * x_j\n",
    "\n",
    "class LightGCN(nn.Module):\n",
    "    def __init__(self, num_nodes, embedding_dim=64, num_layers=3):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(num_nodes, embedding_dim)\n",
    "        nn.init.xavier_uniform_(self.embedding.weight)\n",
    "\n",
    "        self.convs = nn.ModuleList([LightGCNConv() for _ in range(num_layers)])\n",
    "\n",
    "    def forward(self, edge_index):\n",
    "        x = self.embedding.weight\n",
    "        all_embeddings = [x]\n",
    "        for conv in self.convs:\n",
    "            x = conv(x, edge_index)\n",
    "            all_embeddings.append(x)\n",
    "        # Mean of all layer embeddings\n",
    "        x = torch.mean(torch.stack(all_embeddings, dim=0), dim=0)\n",
    "        return x\n",
    "\n",
    "    def get_embedding(self, edge_index):\n",
    "        return self.forward(edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 9: LightGCN with Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightGCNConvWithAttention(MessagePassing):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__(aggr='add')\n",
    "        self.att = nn.Parameter(torch.Tensor(1, in_channels * 2))\n",
    "        nn.init.xavier_uniform_(self.att)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        return self.propagate(edge_index, x=x)\n",
    "\n",
    "    def message(self, x_i, x_j):\n",
    "        x_cat = torch.cat([x_i, x_j], dim=-1)\n",
    "        alpha = F.leaky_relu((x_cat * self.att).sum(dim=-1))\n",
    "        alpha = F.softmax(alpha, dim=0)\n",
    "        return alpha.unsqueeze(-1) * x_j\n",
    "\n",
    "\n",
    "class LightGCNWithAttention(nn.Module):\n",
    "    def __init__(self, num_nodes, embedding_dim=256, num_layers=4, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(num_nodes, embedding_dim)\n",
    "        self.layer_norm = nn.LayerNorm(embedding_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        nn.init.xavier_uniform_(self.embedding.weight)\n",
    "\n",
    "        self.convs = nn.ModuleList([\n",
    "            LightGCNConvWithAttention(embedding_dim) for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, edge_index):\n",
    "        x = self.embedding.weight\n",
    "        all_embeddings = [x]\n",
    "\n",
    "        for conv in self.convs:\n",
    "            x = conv(x, edge_index)\n",
    "            x = self.layer_norm(x)\n",
    "            x = self.dropout(x)\n",
    "            all_embeddings.append(x)\n",
    "\n",
    "        return torch.stack(all_embeddings, dim=0).sum(dim=0)\n",
    "\n",
    "    def get_embedding(self, edge_index):\n",
    "        embeddings = self.forward(edge_index)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 10: Training and Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bpr_loss(user_emb, pos_item_emb, neg_item_emb):\n",
    "    pos_scores = (user_emb * pos_item_emb).sum(dim=1)\n",
    "    neg_scores = (user_emb * neg_item_emb).sum(dim=1)\n",
    "    loss = -torch.log(torch.sigmoid(pos_scores - neg_scores)).mean()\n",
    "    return loss\n",
    "\n",
    "def hybrid_loss(user_emb, pos_item_emb, neg_item_emb, pred_ratings, true_ratings, alpha=0.3):\n",
    "    # RMSE Loss\n",
    "    rmse_loss = torch.sqrt(F.mse_loss(pred_ratings, true_ratings))\n",
    "    \n",
    "    # BPR Loss\n",
    "    pos_scores = (user_emb * pos_item_emb).sum(dim=1)\n",
    "    neg_scores = (user_emb * neg_item_emb).sum(dim=1)\n",
    "    bpr_loss = -torch.log(torch.sigmoid(pos_scores - neg_scores)).mean()\n",
    "    \n",
    "    # Weighted combination\n",
    "    return alpha * rmse_loss + (1 - alpha) * bpr_loss\n",
    "\n",
    "\n",
    "\n",
    "def train_one_epoch(model, optimizer, edge_index, user, item, rating, num_items, alpha=0.3):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Get embeddings\n",
    "    embeddings = model.get_embedding(edge_index)\n",
    "    user_emb = embeddings[user]\n",
    "    pos_item_emb = embeddings[item]\n",
    "\n",
    "    # Negative sampling: randomly select negative items\n",
    "    neg_items = torch.randint(0, num_items, (len(user),), device=device)\n",
    "    neg_item_emb = embeddings[neg_items + num_users]\n",
    "\n",
    "    # Predict ratings for positive samples\n",
    "    pred_ratings = (user_emb * pos_item_emb).sum(dim=1)\n",
    "\n",
    "    # Calculate hybrid loss\n",
    "    loss = hybrid_loss(user_emb, pos_item_emb, neg_item_emb, pred_ratings, rating, alpha)\n",
    "\n",
    "    # Add L2 regularization (on embeddings)\n",
    "    l2_reg = 1e-4 * torch.norm(model.embedding.weight)\n",
    "    loss += l2_reg\n",
    "\n",
    "    # Add L2 regularization for attention (only for LightGCNWithAttention)\n",
    "    if hasattr(model, 'convs') and isinstance(model.convs[0], LightGCNConvWithAttention):\n",
    "        for conv in model.convs:\n",
    "            if hasattr(conv, 'att'):  # Check if 'att' exists\n",
    "                loss += 1e-5 * torch.norm(conv.att)\n",
    "\n",
    "    # Backpropagation and optimizer step\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_rmse(model, edge_index, user, item, rating):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        embeddings = model.get_embedding(edge_index)\n",
    "        user_emb = embeddings[user]\n",
    "        item_emb = embeddings[item]\n",
    "        pred = (user_emb * item_emb).sum(dim=1)\n",
    "        pred = torch.clamp(pred, min=0.0, max=5.0)\n",
    "        true = rating.cpu().numpy()\n",
    "        return rmse(true, pred.cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 11: Training Loops and Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Baseline LightGCN...\n",
      "Epoch 001: Loss=1.3215, Train_RMSE=3.0027, Test_RMSE=3.0015\n",
      "Epoch 002: Loss=1.2366, Train_RMSE=2.7394, Test_RMSE=2.7404\n",
      "Epoch 003: Loss=1.1133, Train_RMSE=2.3881, Test_RMSE=2.3909\n",
      "Epoch 004: Loss=0.9597, Train_RMSE=1.9871, Test_RMSE=1.9905\n",
      "Epoch 005: Loss=0.7950, Train_RMSE=1.6344, Test_RMSE=1.6367\n",
      "Epoch 006: Loss=0.6682, Train_RMSE=1.4315, Test_RMSE=1.4327\n",
      "Epoch 007: Loss=0.6464, Train_RMSE=1.3615, Test_RMSE=1.3626\n",
      "Epoch 008: Loss=0.6841, Train_RMSE=1.3326, Test_RMSE=1.3333\n",
      "Epoch 009: Loss=0.6914, Train_RMSE=1.2955, Test_RMSE=1.2970\n",
      "Epoch 010: Loss=0.6531, Train_RMSE=1.2398, Test_RMSE=1.2438\n",
      "Epoch 011: Loss=0.5840, Train_RMSE=1.1801, Test_RMSE=1.1883\n",
      "Epoch 012: Loss=0.5219, Train_RMSE=1.1577, Test_RMSE=1.1716\n",
      "Epoch 013: Loss=0.4891, Train_RMSE=1.1981, Test_RMSE=1.2164\n",
      "Epoch 014: Loss=0.4959, Train_RMSE=1.2665, Test_RMSE=1.2874\n",
      "Epoch 015: Loss=0.5182, Train_RMSE=1.3165, Test_RMSE=1.3391\n",
      "Epoch 016: Loss=0.5354, Train_RMSE=1.3291, Test_RMSE=1.3527\n",
      "Epoch 017: Loss=0.5394, Train_RMSE=1.3063, Test_RMSE=1.3309\n",
      "Epoch 018: Loss=0.5308, Train_RMSE=1.2611, Test_RMSE=1.2861\n",
      "Early stopping triggered.\n",
      "Baseline LightGCN - Test RMSE: 1.1716, Recall@10: 0.0800\n",
      "\n",
      "Training LightGCN with Attention...\n",
      "Epoch 001: Loss=1.2865, Train_RMSE=3.6532, Test_RMSE=3.6506\n",
      "Epoch 002: Loss=1.2863, Train_RMSE=3.6528, Test_RMSE=3.6503\n",
      "Epoch 003: Loss=1.2861, Train_RMSE=3.6520, Test_RMSE=3.6495\n",
      "Epoch 004: Loss=1.2858, Train_RMSE=3.6507, Test_RMSE=3.6482\n",
      "Epoch 005: Loss=1.2854, Train_RMSE=3.6489, Test_RMSE=3.6465\n",
      "Epoch 006: Loss=1.2849, Train_RMSE=3.6467, Test_RMSE=3.6443\n",
      "Epoch 007: Loss=1.2842, Train_RMSE=3.6439, Test_RMSE=3.6415\n",
      "Epoch 008: Loss=1.2834, Train_RMSE=3.6407, Test_RMSE=3.6383\n",
      "Epoch 009: Loss=1.2824, Train_RMSE=3.6368, Test_RMSE=3.6345\n",
      "Epoch 010: Loss=1.2814, Train_RMSE=3.6324, Test_RMSE=3.6301\n",
      "Epoch 011: Loss=1.2800, Train_RMSE=3.6274, Test_RMSE=3.6251\n",
      "Epoch 012: Loss=1.2785, Train_RMSE=3.6218, Test_RMSE=3.6195\n",
      "Epoch 013: Loss=1.2768, Train_RMSE=3.6155, Test_RMSE=3.6133\n",
      "Epoch 014: Loss=1.2749, Train_RMSE=3.6085, Test_RMSE=3.6064\n",
      "Epoch 015: Loss=1.2727, Train_RMSE=3.6008, Test_RMSE=3.5988\n",
      "Epoch 016: Loss=1.2704, Train_RMSE=3.5924, Test_RMSE=3.5904\n",
      "Epoch 017: Loss=1.2679, Train_RMSE=3.5833, Test_RMSE=3.5813\n",
      "Epoch 018: Loss=1.2649, Train_RMSE=3.5733, Test_RMSE=3.5715\n",
      "Epoch 019: Loss=1.2619, Train_RMSE=3.5626, Test_RMSE=3.5609\n",
      "Epoch 020: Loss=1.2588, Train_RMSE=3.5511, Test_RMSE=3.5494\n",
      "Epoch 021: Loss=1.2551, Train_RMSE=3.5387, Test_RMSE=3.5372\n",
      "Epoch 022: Loss=1.2514, Train_RMSE=3.5255, Test_RMSE=3.5241\n",
      "Epoch 023: Loss=1.2473, Train_RMSE=3.5114, Test_RMSE=3.5101\n",
      "Epoch 024: Loss=1.2432, Train_RMSE=3.4963, Test_RMSE=3.4952\n",
      "Epoch 025: Loss=1.2382, Train_RMSE=3.4804, Test_RMSE=3.4794\n",
      "Epoch 026: Loss=1.2333, Train_RMSE=3.4635, Test_RMSE=3.4627\n",
      "Epoch 027: Loss=1.2282, Train_RMSE=3.4457, Test_RMSE=3.4450\n",
      "Epoch 028: Loss=1.2219, Train_RMSE=3.4269, Test_RMSE=3.4264\n",
      "Epoch 029: Loss=1.2166, Train_RMSE=3.4071, Test_RMSE=3.4068\n",
      "Epoch 030: Loss=1.2105, Train_RMSE=3.3863, Test_RMSE=3.3861\n",
      "Epoch 031: Loss=1.2038, Train_RMSE=3.3644, Test_RMSE=3.3645\n",
      "Epoch 032: Loss=1.1973, Train_RMSE=3.3415, Test_RMSE=3.3419\n",
      "Epoch 033: Loss=1.1907, Train_RMSE=3.3176, Test_RMSE=3.3182\n",
      "Epoch 034: Loss=1.1827, Train_RMSE=3.2926, Test_RMSE=3.2934\n",
      "Epoch 035: Loss=1.1756, Train_RMSE=3.2666, Test_RMSE=3.2676\n",
      "Epoch 036: Loss=1.1661, Train_RMSE=3.2394, Test_RMSE=3.2408\n",
      "Epoch 037: Loss=1.1589, Train_RMSE=3.2112, Test_RMSE=3.2128\n",
      "Epoch 038: Loss=1.1507, Train_RMSE=3.1819, Test_RMSE=3.1838\n",
      "Epoch 039: Loss=1.1415, Train_RMSE=3.1514, Test_RMSE=3.1536\n",
      "Epoch 040: Loss=1.1321, Train_RMSE=3.1199, Test_RMSE=3.1224\n",
      "Epoch 041: Loss=1.1217, Train_RMSE=3.0872, Test_RMSE=3.0901\n",
      "Epoch 042: Loss=1.1115, Train_RMSE=3.0534, Test_RMSE=3.0567\n",
      "Epoch 043: Loss=1.1024, Train_RMSE=3.0185, Test_RMSE=3.0221\n",
      "Epoch 044: Loss=1.0911, Train_RMSE=2.9825, Test_RMSE=2.9865\n",
      "Epoch 045: Loss=1.0796, Train_RMSE=2.9454, Test_RMSE=2.9498\n",
      "Epoch 046: Loss=1.0692, Train_RMSE=2.9071, Test_RMSE=2.9119\n",
      "Epoch 047: Loss=1.0573, Train_RMSE=2.8678, Test_RMSE=2.8730\n",
      "Epoch 048: Loss=1.0465, Train_RMSE=2.8273, Test_RMSE=2.8330\n",
      "Epoch 049: Loss=1.0332, Train_RMSE=2.7858, Test_RMSE=2.7919\n",
      "Epoch 050: Loss=1.0215, Train_RMSE=2.7431, Test_RMSE=2.7498\n",
      "Epoch 051: Loss=1.0110, Train_RMSE=2.6995, Test_RMSE=2.7067\n",
      "Epoch 052: Loss=0.9968, Train_RMSE=2.6548, Test_RMSE=2.6625\n",
      "Epoch 053: Loss=0.9845, Train_RMSE=2.6091, Test_RMSE=2.6173\n",
      "Epoch 054: Loss=0.9693, Train_RMSE=2.5624, Test_RMSE=2.5712\n",
      "Epoch 055: Loss=0.9564, Train_RMSE=2.5148, Test_RMSE=2.5241\n",
      "Epoch 056: Loss=0.9427, Train_RMSE=2.4662, Test_RMSE=2.4761\n",
      "Epoch 057: Loss=0.9286, Train_RMSE=2.4167, Test_RMSE=2.4273\n",
      "Epoch 058: Loss=0.9145, Train_RMSE=2.3664, Test_RMSE=2.3776\n",
      "Epoch 059: Loss=0.9036, Train_RMSE=2.3153, Test_RMSE=2.3271\n",
      "Epoch 060: Loss=0.8879, Train_RMSE=2.2634, Test_RMSE=2.2759\n",
      "Epoch 061: Loss=0.8730, Train_RMSE=2.2109, Test_RMSE=2.2241\n",
      "Epoch 062: Loss=0.8550, Train_RMSE=2.1577, Test_RMSE=2.1716\n",
      "Epoch 063: Loss=0.8418, Train_RMSE=2.1040, Test_RMSE=2.1186\n",
      "Epoch 064: Loss=0.8273, Train_RMSE=2.0499, Test_RMSE=2.0652\n",
      "Epoch 065: Loss=0.8120, Train_RMSE=1.9953, Test_RMSE=2.0114\n",
      "Epoch 066: Loss=0.7965, Train_RMSE=1.9406, Test_RMSE=1.9574\n",
      "Epoch 067: Loss=0.7818, Train_RMSE=1.8857, Test_RMSE=1.9033\n",
      "Epoch 068: Loss=0.7669, Train_RMSE=1.8308, Test_RMSE=1.8493\n",
      "Epoch 069: Loss=0.7502, Train_RMSE=1.7762, Test_RMSE=1.7954\n",
      "Epoch 070: Loss=0.7380, Train_RMSE=1.7219, Test_RMSE=1.7419\n",
      "Epoch 071: Loss=0.7234, Train_RMSE=1.6682, Test_RMSE=1.6890\n",
      "Epoch 072: Loss=0.7087, Train_RMSE=1.6153, Test_RMSE=1.6369\n",
      "Epoch 073: Loss=0.6954, Train_RMSE=1.5634, Test_RMSE=1.5858\n",
      "Epoch 074: Loss=0.6787, Train_RMSE=1.5128, Test_RMSE=1.5361\n",
      "Epoch 075: Loss=0.6674, Train_RMSE=1.4638, Test_RMSE=1.4879\n",
      "Epoch 076: Loss=0.6584, Train_RMSE=1.4167, Test_RMSE=1.4415\n",
      "Epoch 077: Loss=0.6456, Train_RMSE=1.3720, Test_RMSE=1.3975\n",
      "Epoch 078: Loss=0.6301, Train_RMSE=1.3298, Test_RMSE=1.3559\n",
      "Epoch 079: Loss=0.6225, Train_RMSE=1.2907, Test_RMSE=1.3174\n",
      "Epoch 080: Loss=0.6093, Train_RMSE=1.2548, Test_RMSE=1.2820\n",
      "Epoch 081: Loss=0.6013, Train_RMSE=1.2225, Test_RMSE=1.2501\n",
      "Epoch 082: Loss=0.5896, Train_RMSE=1.1939, Test_RMSE=1.2217\n",
      "Epoch 083: Loss=0.5805, Train_RMSE=1.1689, Test_RMSE=1.1970\n",
      "Epoch 084: Loss=0.5744, Train_RMSE=1.1479, Test_RMSE=1.1761\n",
      "Epoch 085: Loss=0.5699, Train_RMSE=1.1306, Test_RMSE=1.1588\n",
      "Epoch 086: Loss=0.5657, Train_RMSE=1.1170, Test_RMSE=1.1451\n",
      "Epoch 087: Loss=0.5603, Train_RMSE=1.1067, Test_RMSE=1.1347\n",
      "Epoch 088: Loss=0.5557, Train_RMSE=1.0996, Test_RMSE=1.1273\n",
      "Epoch 089: Loss=0.5547, Train_RMSE=1.0950, Test_RMSE=1.1225\n",
      "Epoch 090: Loss=0.5518, Train_RMSE=1.0926, Test_RMSE=1.1197\n",
      "Epoch 091: Loss=0.5510, Train_RMSE=1.0918, Test_RMSE=1.1186\n",
      "Epoch 092: Loss=0.5534, Train_RMSE=1.0921, Test_RMSE=1.1187\n",
      "Epoch 093: Loss=0.5488, Train_RMSE=1.0931, Test_RMSE=1.1195\n",
      "Epoch 094: Loss=0.5499, Train_RMSE=1.0945, Test_RMSE=1.1206\n",
      "Epoch 095: Loss=0.5494, Train_RMSE=1.0958, Test_RMSE=1.1218\n",
      "Epoch 096: Loss=0.5512, Train_RMSE=1.0969, Test_RMSE=1.1229\n",
      "Epoch 097: Loss=0.5494, Train_RMSE=1.0977, Test_RMSE=1.1236\n",
      "Early stopping triggered.\n",
      "LightGCN+Attention - Test RMSE: 1.1186, Recall@10: 0.0531\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "def train_model(model, edge_index, train_user, train_item, train_rating, \n",
    "                test_user, test_item, test_rating, \n",
    "                num_items, alpha=0.2, epochs=50, lr=0.001, weight_decay=1e-5):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    best_rmse = float('inf')\n",
    "    best_state = None\n",
    "    patience = 5\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        loss = train_one_epoch(model, optimizer, edge_index, train_user, train_item, train_rating, num_items, alpha)\n",
    "        tr_rmse = evaluate_rmse(model, edge_index, train_user, train_item, train_rating)\n",
    "        val_rmse = evaluate_rmse(model, edge_index, test_user, test_item, test_rating)\n",
    "        \n",
    "        print(f\"Epoch {epoch:03d}: Loss={loss:.4f}, Train_RMSE={tr_rmse:.4f}, Test_RMSE={val_rmse:.4f}\")\n",
    "\n",
    "        # Early stopping on validation RMSE\n",
    "        if tr_rmse < best_rmse:\n",
    "            best_rmse = tr_rmse\n",
    "            best_state = copy.deepcopy(model.state_dict())\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter > patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(best_state)\n",
    "    return model\n",
    "\n",
    "\n",
    "# Train the baseline model\n",
    "baseline_model = LightGCN(num_nodes=num_nodes, embedding_dim=64, num_layers=3).to(device)\n",
    "print(\"Training Baseline LightGCN...\")\n",
    "baseline_model = train_model(baseline_model, data.edge_index, train_user, train_item, train_rating, \n",
    "                             test_user, test_item, test_rating, num_items, alpha=0.3)\n",
    "\n",
    "baseline_rmse = evaluate_rmse(baseline_model, data.edge_index, test_user, test_item, test_rating)\n",
    "baseline_recall = recall_at_k(baseline_model, k=10)\n",
    "print(f\"Baseline LightGCN - Test RMSE: {baseline_rmse:.4f}, Recall@10: {baseline_recall:.4f}\")\n",
    "\n",
    "# Train the LightGCN with Attention model\n",
    "att_model = LightGCNWithAttention(num_nodes=num_nodes, embedding_dim=64, num_layers=3, dropout=0.4).to(device)\n",
    "print(\"\\nTraining LightGCN with Attention...\")\n",
    "att_model = train_model(att_model, data.edge_index, train_user, train_item, train_rating, \n",
    "                        test_user, test_item, test_rating, num_items, alpha=0.2, \n",
    "                        epochs=400, lr=0.0005, weight_decay=1e-4)\n",
    "\n",
    "att_rmse = evaluate_rmse(att_model, data.edge_index, test_user, test_item, test_rating)\n",
    "att_recall = recall_at_k(att_model, k=10)\n",
    "print(f\"LightGCN+Attention - Test RMSE: {att_rmse:.4f}, Recall@10: {att_recall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 12: Results Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Final Comparison =====\n",
      "Baseline LightGCN    : RMSE = 1.1716, Recall@10 = 0.0800\n",
      "LightGCN + Attention : RMSE = 1.1186, Recall@10 = 0.0531\n"
     ]
    }
   ],
   "source": [
    "print(\"===== Final Comparison =====\")\n",
    "print(f\"Baseline LightGCN    : RMSE = {baseline_rmse:.4f}, Recall@10 = {baseline_recall:.4f}\")\n",
    "print(f\"LightGCN + Attention : RMSE = {att_rmse:.4f}, Recall@10 = {att_recall:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rtl05MBeZVbH"
   },
   "source": [
    "# **Recommender Systems with Graph Neural Networks on MovieLens**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GA2venLVZgzJ"
   },
   "source": [
    "## Setting up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15182,
     "status": "ok",
     "timestamp": 1733813023360,
     "user": {
      "displayName": "Renee Duarte White",
      "userId": "06749715926337474207"
     },
     "user_tz": 480
    },
    "id": "w_k2fJa3Ze_H",
    "outputId": "70dd3e43-0ad3-49c6-ebdf-7f28ab5e4234"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
      "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
      "Collecting torch-geometric\n",
      "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.11.9)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2024.10.0)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.26.4)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.2.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric) (1.18.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2024.8.30)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch-geometric) (4.12.2)\n",
      "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torch-geometric\n",
      "Successfully installed torch-geometric-2.6.1\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio\n",
    "!pip install torch-geometric\n",
    "!pip install pandas numpy scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vUf40l14aWve"
   },
   "source": [
    "## Loading and preprocessing the MovieLens-Latest-Small dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EztReHQ7ag6n"
   },
   "source": [
    "### Loading the dataset using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 357,
     "status": "ok",
     "timestamp": 1733813095940,
     "user": {
      "displayName": "Renee Duarte White",
      "userId": "06749715926337474207"
     },
     "user_tz": 480
    },
    "id": "EhWl_N7yac76"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ratings = pd.read_csv('ml-latest-small/ratings.csv')\n",
    "movies = pd.read_csv('ml-latest-small/movies.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AMetd0cvaqqK"
   },
   "source": [
    "### Encode Users and Items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1733813096432,
     "user": {
      "displayName": "Renee Duarte White",
      "userId": "06749715926337474207"
     },
     "user_tz": 480
    },
    "id": "_LBriH6Gato6"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "ratings = ratings[ratings['userId'].notna()]\n",
    "\n",
    "user_id_mapping = {id: idx for idx, id in enumerate(ratings['userId'].unique())}\n",
    "item_id_mapping = {id: idx for idx, id in enumerate(ratings['movieId'].unique())}\n",
    "\n",
    "ratings.loc[:, 'userId'] = ratings['userId'].map(user_id_mapping)\n",
    "ratings.loc[:, 'movieId'] = ratings['movieId'].map(item_id_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n6eQSUyhbG8e"
   },
   "source": [
    "## Building the user-item interaction graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m6F0mAqWb3aP"
   },
   "source": [
    "###  Build the bipartite graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 956,
     "status": "ok",
     "timestamp": 1733816162656,
     "user": {
      "displayName": "Renee Duarte White",
      "userId": "06749715926337474207"
     },
     "user_tz": 480
    },
    "id": "0YdEmvOqb6mT",
    "outputId": "3a44f779-8a3a-4f99-bce7-72c8259fbc5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# 1. First, add device configuration at the start\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "num_users = ratings['userId'].nunique()\n",
    "num_items = ratings['movieId'].nunique()\n",
    "num_nodes = num_users + num_items\n",
    "\n",
    "user_nodes = ratings['userId'].to_numpy()\n",
    "item_nodes = ratings['movieId'].to_numpy() + num_users\n",
    "\n",
    "edge_index = np.vstack((user_nodes, item_nodes))\n",
    "edge_attr = torch.tensor(ratings['rating'].to_numpy(), dtype=torch.float)\n",
    "\n",
    "x = torch.eye(num_nodes)\n",
    "data = Data(x=x, edge_index=torch.tensor(edge_index, dtype=torch.long), edge_attr=edge_attr)\n",
    "\n",
    "data = data.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fSI2YCXVcHys"
   },
   "source": [
    "## Implementing the LightGCN model with attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1733816162657,
     "user": {
      "displayName": "Renee Duarte White",
      "userId": "06749715926337474207"
     },
     "user_tz": 480
    },
    "id": "HjoSMzHDcLCZ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import degree\n",
    "\n",
    "# Step 1: Implementing LightGCN Layer with Attention\n",
    "class LightGCNConv(MessagePassing):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(LightGCNConv, self).__init__(aggr='add', **kwargs)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        row, col = edge_index\n",
    "        deg = degree(col, x.size(0), dtype=x.dtype)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "\n",
    "        return self.propagate(edge_index, x=x, norm=norm)\n",
    "\n",
    "    def message(self, x_j, norm):\n",
    "        return norm.view(-1, 1) * x_j\n",
    "\n",
    "# Step 2: Incorporating Attention Mechanisms\n",
    "class LightGCNConvWithAttention(MessagePassing):\n",
    "    def __init__(self, in_channels):\n",
    "        super(LightGCNConvWithAttention, self).__init__(aggr='add')\n",
    "        self.att = torch.nn.Parameter(torch.Tensor(1, in_channels * 2))\n",
    "        torch.nn.init.xavier_uniform_(self.att)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        return self.propagate(edge_index, x=x)\n",
    "\n",
    "    def message(self, x_i, x_j):\n",
    "        x_cat = torch.cat([x_i, x_j], dim=-1)\n",
    "        alpha = F.leaky_relu((x_cat * self.att).sum(dim=-1))\n",
    "        alpha = F.softmax(alpha, dim=0)\n",
    "        return alpha.unsqueeze(-1) * x_j\n",
    "\n",
    "# Step 3: Defining the Complete Model\n",
    "class LightGCNWithAttention(torch.nn.Module):\n",
    "    def __init__(self, num_nodes, embedding_dim=256, num_layers=4, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = torch.nn.Embedding(num_nodes, embedding_dim)\n",
    "        self.layer_norm = torch.nn.LayerNorm(embedding_dim)\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        torch.nn.init.xavier_uniform_(self.embedding.weight)\n",
    "\n",
    "        self.convs = torch.nn.ModuleList([\n",
    "            LightGCNConvWithAttention(embedding_dim) for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, edge_index):\n",
    "        x = self.embedding.weight\n",
    "        all_embeddings = [x]\n",
    "\n",
    "        for conv in self.convs:\n",
    "            x = conv(x, edge_index)\n",
    "            x = self.layer_norm(x)\n",
    "            x = self.dropout(x)\n",
    "            all_embeddings.append(x)\n",
    "\n",
    "        return torch.stack(all_embeddings, dim=0).mean(dim=0)\n",
    "\n",
    "    def get_embedding(self, edge_index):\n",
    "        embeddings = self.forward(edge_index)\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "at1R1FYIcxyb"
   },
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D07jopPCap8u"
   },
   "source": [
    "### Preparing Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1733816162657,
     "user": {
      "displayName": "Renee Duarte White",
      "userId": "06749715926337474207"
     },
     "user_tz": 480
    },
    "id": "zy-iZCcqanCF"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data\n",
    "train_data, test_data = train_test_split(ratings, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create edge indices for training\n",
    "train_edge_index = np.vstack((\n",
    "    train_data['userId'].to_numpy(),\n",
    "    train_data['movieId'].to_numpy() + num_users\n",
    "))\n",
    "train_edge_index = torch.tensor(train_edge_index, dtype=torch.long)\n",
    "\n",
    "test_edge_index = np.vstack((\n",
    "    test_data['userId'].to_numpy(),\n",
    "    test_data['movieId'].to_numpy() + num_users\n",
    "))\n",
    "\n",
    "test_edge_index = torch.tensor(test_edge_index, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kvyakK9nazpx"
   },
   "source": [
    "### Defining Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "executionInfo": {
     "elapsed": 291,
     "status": "ok",
     "timestamp": 1733816629687,
     "user": {
      "displayName": "Renee Duarte White",
      "userId": "06749715926337474207"
     },
     "user_tz": 480
    },
    "id": "v63-g60Ma6a6"
   },
   "outputs": [],
   "source": [
    "model = LightGCNWithAttention(\n",
    "    num_nodes=num_nodes,\n",
    "    embedding_dim=256,\n",
    "    num_layers=4,\n",
    "    dropout=0.2\n",
    ")\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=5, min_lr=1e-5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zJOUWG-la7tQ"
   },
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "executionInfo": {
     "elapsed": 779,
     "status": "ok",
     "timestamp": 1733816630463,
     "user": {
      "displayName": "Renee Duarte White",
      "userId": "06749715926337474207"
     },
     "user_tz": 480
    },
    "id": "ngySUWjOa9t4"
   },
   "outputs": [],
   "source": [
    "# 2. Move model to device\n",
    "model = model.to(device)\n",
    "\n",
    "# 3. Update training function with device handling\n",
    "def train(model, optimizer):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Get embeddings\n",
    "    embeddings = model.get_embedding(data.edge_index.to(device))\n",
    "\n",
    "    # Sample negative items\n",
    "    batch_size = train_data['userId'].shape[0]\n",
    "    neg_items = torch.randint(0, num_items, (batch_size,), device=device)\n",
    "\n",
    "    # Get embeddings for users, positive and negative items\n",
    "    user_emb = embeddings[train_data['userId'].to_numpy()].to(device)\n",
    "    pos_item_emb = embeddings[train_data['movieId'].to_numpy() + num_users].to(device)\n",
    "    neg_item_emb = embeddings[neg_items + num_users].to(device)\n",
    "\n",
    "    # BPR loss\n",
    "    pos_scores = (user_emb * pos_item_emb).sum(dim=1)\n",
    "    neg_scores = (user_emb * neg_item_emb).sum(dim=1)\n",
    "    loss = -torch.log(torch.sigmoid(pos_scores - neg_scores)).mean()\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9YA22N9RbCc_"
   },
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tb_dQUepbHH3"
   },
   "source": [
    "### RMSE on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1733816630464,
     "user": {
      "displayName": "Renee Duarte White",
      "userId": "06749715926337474207"
     },
     "user_tz": 480
    },
    "id": "rYdDHI-2bDw5"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import root_mean_squared_error\n",
    "\n",
    "def test(model):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        embeddings = model.get_embedding(data.edge_index.to(device))\n",
    "        user_emb = embeddings[test_data['userId'].to_numpy()].to(device)\n",
    "        item_emb = embeddings[test_data['movieId'].to_numpy() + num_users].to(device)\n",
    "        preds = (user_emb * item_emb).sum(dim=1)\n",
    "        rmse = root_mean_squared_error(test_data['rating'], preds.cpu().numpy())\n",
    "    return rmse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a7LAB9EebKT7"
   },
   "source": [
    "### Recall@K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1733816630464,
     "user": {
      "displayName": "Renee Duarte White",
      "userId": "06749715926337474207"
     },
     "user_tz": 480
    },
    "id": "udf4g5tibMK1"
   },
   "outputs": [],
   "source": [
    "def recall_at_k(model, edge_index, k=10):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Get embeddings\n",
    "        embeddings = model.get_embedding(edge_index.to(device))\n",
    "\n",
    "        # Separate user and item embeddings\n",
    "        user_emb = embeddings[:num_users]\n",
    "        item_emb = embeddings[num_users:num_users+num_items]\n",
    "\n",
    "        # Calculate scores for all user-item pairs\n",
    "        scores = torch.mm(user_emb, item_emb.t())\n",
    "\n",
    "        # Get top k items for each user\n",
    "        _, top_k_items = scores.topk(k=k, dim=1)\n",
    "\n",
    "        # Move tensors to CPU for numpy operations\n",
    "        top_k_items = top_k_items.cpu()\n",
    "        edge_index = edge_index.cpu()\n",
    "\n",
    "        # Calculate recall\n",
    "        hits = torch.zeros(num_users)\n",
    "        for i in range(num_users):\n",
    "            relevant_items = set((edge_index[1][edge_index[0] == i] - num_users).numpy())\n",
    "            recommended_items = set(top_k_items[i].numpy())\n",
    "            hits[i] = len(relevant_items & recommended_items) / len(relevant_items) if len(relevant_items) > 0 else 0\n",
    "\n",
    "        return hits.mean().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1733816630464,
     "user": {
      "displayName": "Renee Duarte White",
      "userId": "06749715926337474207"
     },
     "user_tz": 480
    },
    "id": "81j3LvW0WUfJ"
   },
   "outputs": [],
   "source": [
    "def precision_at_k(model, edge_index, k=10):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Get embeddings\n",
    "        embeddings = model.get_embedding(edge_index.to(device))\n",
    "\n",
    "        # Separate user and item embeddings\n",
    "        user_emb = embeddings[:num_users]\n",
    "        item_emb = embeddings[num_users:num_users+num_items]\n",
    "\n",
    "        # Calculate scores for all user-item pairs\n",
    "        scores = torch.mm(user_emb, item_emb.t())\n",
    "\n",
    "        # Get top k items for each user\n",
    "        _, top_k_items = scores.topk(k=k, dim=1)\n",
    "\n",
    "        # Move tensors to CPU for numpy operations\n",
    "        top_k_items = top_k_items.cpu()\n",
    "        edge_index = edge_index.cpu()\n",
    "\n",
    "        # Calculate precision\n",
    "        precision_scores = torch.zeros(num_users)\n",
    "        for i in range(num_users):\n",
    "            relevant_items = set((edge_index[1][edge_index[0] == i] - num_users).numpy())\n",
    "            recommended_items = set(top_k_items[i].numpy())\n",
    "            hits = len(relevant_items & recommended_items)\n",
    "            precision_scores[i] = hits / k  # Precision is hits divided by k\n",
    "\n",
    "        return precision_scores.mean().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kMJJGXG9bTB5"
   },
   "source": [
    "## Putting It All Together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HVhB_MWlbVD_"
   },
   "source": [
    "### Training and Evaluation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4530,
     "status": "ok",
     "timestamp": 1733816634986,
     "user": {
      "displayName": "Renee Duarte White",
      "userId": "06749715926337474207"
     },
     "user_tz": 480
    },
    "id": "fMD6UmXHbXtq",
    "outputId": "f656a379-a97e-4606-ea53-62836f65c65b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6931, RMSE: 3.6511, Recall@10: 0.0117, Precision@10: 0.0280\n",
      "Epoch 2, Loss: 0.6931, RMSE: 3.6506, Recall@10: 0.0489, Precision@10: 0.0887\n",
      "Epoch 3, Loss: 0.6931, RMSE: 3.6497, Recall@10: 0.0543, Precision@10: 0.0926\n",
      "Epoch 4, Loss: 0.6930, RMSE: 3.6483, Recall@10: 0.0544, Precision@10: 0.0915\n",
      "Epoch 5, Loss: 0.6928, RMSE: 3.6466, Recall@10: 0.0541, Precision@10: 0.0902\n",
      "Epoch 6, Loss: 0.6926, RMSE: 3.6443, Recall@10: 0.0542, Precision@10: 0.0898\n",
      "Epoch 7, Loss: 0.6923, RMSE: 3.6415, Recall@10: 0.0538, Precision@10: 0.0898\n",
      "Epoch 8, Loss: 0.6919, RMSE: 3.6383, Recall@10: 0.0527, Precision@10: 0.0885\n",
      "Epoch 9, Loss: 0.6915, RMSE: 3.6344, Recall@10: 0.0525, Precision@10: 0.0885\n",
      "Epoch 10, Loss: 0.6909, RMSE: 3.6300, Recall@10: 0.0525, Precision@10: 0.0885\n",
      "Epoch 11, Loss: 0.6903, RMSE: 3.6250, Recall@10: 0.0523, Precision@10: 0.0884\n",
      "Epoch 12, Loss: 0.6896, RMSE: 3.6194, Recall@10: 0.0526, Precision@10: 0.0887\n",
      "Epoch 13, Loss: 0.6888, RMSE: 3.6131, Recall@10: 0.0531, Precision@10: 0.0890\n",
      "Epoch 14, Loss: 0.6879, RMSE: 3.6061, Recall@10: 0.0536, Precision@10: 0.0893\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-139-42c8ed27003e>:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(save_file))\n"
     ]
    }
   ],
   "source": [
    "def train_and_test(model, optimizer, scheduler, save_file):\n",
    "    best_recall = 0\n",
    "    patience = 10\n",
    "    patience_counter = 0\n",
    "    num_epochs = 200\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        loss = train(model, optimizer)\n",
    "        rmse = test(model)\n",
    "        recall = recall_at_k(model, test_edge_index, k=10)\n",
    "        precision = precision_at_k(model, test_edge_index, k=10)\n",
    "\n",
    "        print(f'Epoch {epoch+1}, Loss: {loss:.4f}, RMSE: {rmse:.4f}, Recall@10: {recall:.4f}, Precision@10: {precision:.4f}')\n",
    "\n",
    "        scheduler.step(loss)\n",
    "\n",
    "        if recall > best_recall:\n",
    "            best_recall = recall\n",
    "            torch.save(model.state_dict(), save_file)\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "    # Load best model\n",
    "    model.load_state_dict(torch.load(save_file))\n",
    "\n",
    "train_and_test(model, optimizer, scheduler, 'best_model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SUnM46ViTp_U"
   },
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1733816634987,
     "user": {
      "displayName": "Renee Duarte White",
      "userId": "06749715926337474207"
     },
     "user_tz": 480
    },
    "id": "L5SxCSYqcFMC"
   },
   "outputs": [],
   "source": [
    "# Updated train function\n",
    "def train(model, optimizer):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Get embeddings\n",
    "    embeddings = model.get_embedding(data.edge_index.to(device))\n",
    "    print('test')\n",
    "\n",
    "    pos_rank, neg_rank = model(data.edge_index, train_edge_index).chunk(2)\n",
    "    loss = model.recommendation_loss(\n",
    "            pos_rank,\n",
    "            neg_rank,\n",
    "            node_id=train_edge_index.unique(),\n",
    "    )\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1733816634987,
     "user": {
      "displayName": "Renee Duarte White",
      "userId": "06749715926337474207"
     },
     "user_tz": 480
    },
    "id": "885Gbf6wcLAq"
   },
   "outputs": [],
   "source": [
    "def train_and_test(model, optimizer, scheduler, save_file):\n",
    "    best_recall = 0\n",
    "    patience = 10\n",
    "    patience_counter = 0\n",
    "    num_epochs = 200\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        loss = train(model, optimizer)\n",
    "        rmse = test(model)\n",
    "        recall = recall_at_k(model, test_edge_index, k=10)\n",
    "        precision = precision_at_k(model, test_edge_index, k=10)\n",
    "\n",
    "        print(f'Epoch {epoch+1}, Loss: {loss:.4f}, RMSE: {rmse:.4f}, Recall@10: {recall:.4f}, Precision@10: {precision:.4f}')\n",
    "\n",
    "        scheduler.step(loss)\n",
    "\n",
    "        if recall > best_recall:\n",
    "            best_recall = recall\n",
    "            torch.save(model.state_dict(), save_file)\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "    # Load best model\n",
    "    model.load_state_dict(torch.load(save_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1733816634987,
     "user": {
      "displayName": "Renee Duarte White",
      "userId": "06749715926337474207"
     },
     "user_tz": 480
    },
    "id": "Vs0jZrvOTp_U"
   },
   "outputs": [],
   "source": [
    "from torch_geometric.nn import LightGCN\n",
    "# Initialize the baseline LightGCN model\n",
    "baseline_model = LightGCN(num_nodes=num_nodes, embedding_dim=256, num_layers=4).to(device)\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = torch.optim.Adam(baseline_model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=5, min_lr=1e-5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13423,
     "status": "ok",
     "timestamp": 1733816648385,
     "user": {
      "displayName": "Renee Duarte White",
      "userId": "06749715926337474207"
     },
     "user_tz": 480
    },
    "id": "xUXQziz6Tp_U",
    "outputId": "d8ed1afb-16bb-47b2-b291-f053e2b83d23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "Epoch 1, Loss: 0.6931, RMSE: 3.6514, Recall@10: 0.0005, Precision@10: 0.0039\n",
      "test\n",
      "Epoch 2, Loss: 0.6931, RMSE: 3.6514, Recall@10: 0.0009, Precision@10: 0.0041\n",
      "test\n",
      "Epoch 3, Loss: 0.6931, RMSE: 3.6514, Recall@10: 0.0004, Precision@10: 0.0038\n",
      "test\n",
      "Epoch 4, Loss: 0.6931, RMSE: 3.6514, Recall@10: 0.0005, Precision@10: 0.0038\n",
      "test\n",
      "Epoch 5, Loss: 0.6931, RMSE: 3.6514, Recall@10: 0.0005, Precision@10: 0.0036\n",
      "test\n",
      "Epoch 6, Loss: 0.6931, RMSE: 3.6514, Recall@10: 0.0006, Precision@10: 0.0038\n",
      "test\n",
      "Epoch 7, Loss: 0.6931, RMSE: 3.6514, Recall@10: 0.0007, Precision@10: 0.0038\n",
      "test\n",
      "Epoch 8, Loss: 0.6931, RMSE: 3.6514, Recall@10: 0.0008, Precision@10: 0.0036\n",
      "test\n",
      "Epoch 9, Loss: 0.6931, RMSE: 3.6514, Recall@10: 0.0008, Precision@10: 0.0033\n",
      "test\n",
      "Epoch 10, Loss: 0.6931, RMSE: 3.6514, Recall@10: 0.0008, Precision@10: 0.0031\n",
      "test\n",
      "Epoch 11, Loss: 0.6931, RMSE: 3.6514, Recall@10: 0.0011, Precision@10: 0.0036\n",
      "test\n",
      "Epoch 12, Loss: 0.6931, RMSE: 3.6514, Recall@10: 0.0014, Precision@10: 0.0041\n",
      "test\n",
      "Epoch 13, Loss: 0.6931, RMSE: 3.6514, Recall@10: 0.0016, Precision@10: 0.0043\n",
      "test\n",
      "Epoch 14, Loss: 0.6931, RMSE: 3.6514, Recall@10: 0.0015, Precision@10: 0.0038\n",
      "test\n",
      "Epoch 15, Loss: 0.6931, RMSE: 3.6514, Recall@10: 0.0019, Precision@10: 0.0041\n",
      "test\n",
      "Epoch 16, Loss: 0.6931, RMSE: 3.6514, Recall@10: 0.0021, Precision@10: 0.0046\n",
      "test\n",
      "Epoch 17, Loss: 0.6931, RMSE: 3.6514, Recall@10: 0.0020, Precision@10: 0.0048\n",
      "test\n",
      "Epoch 18, Loss: 0.6931, RMSE: 3.6514, Recall@10: 0.0023, Precision@10: 0.0049\n",
      "test\n",
      "Epoch 19, Loss: 0.6931, RMSE: 3.6514, Recall@10: 0.0023, Precision@10: 0.0051\n",
      "test\n",
      "Epoch 20, Loss: 0.6931, RMSE: 3.6514, Recall@10: 0.0023, Precision@10: 0.0049\n",
      "test\n",
      "Epoch 21, Loss: 0.6931, RMSE: 3.6514, Recall@10: 0.0023, Precision@10: 0.0049\n",
      "test\n",
      "Epoch 22, Loss: 0.6931, RMSE: 3.6514, Recall@10: 0.0023, Precision@10: 0.0046\n",
      "test\n",
      "Epoch 23, Loss: 0.6931, RMSE: 3.6514, Recall@10: 0.0024, Precision@10: 0.0049\n",
      "test\n",
      "Epoch 24, Loss: 0.6931, RMSE: 3.6514, Recall@10: 0.0024, Precision@10: 0.0049\n",
      "test\n",
      "Epoch 25, Loss: 0.6931, RMSE: 3.6514, Recall@10: 0.0024, Precision@10: 0.0049\n",
      "test\n",
      "Epoch 26, Loss: 0.6931, RMSE: 3.6514, Recall@10: 0.0025, Precision@10: 0.0051\n",
      "test\n",
      "Epoch 27, Loss: 0.6931, RMSE: 3.6514, Recall@10: 0.0025, Precision@10: 0.0052\n",
      "test\n",
      "Epoch 28, Loss: 0.6931, RMSE: 3.6514, Recall@10: 0.0026, Precision@10: 0.0054\n",
      "test\n",
      "Epoch 29, Loss: 0.6931, RMSE: 3.6514, Recall@10: 0.0026, Precision@10: 0.0056\n",
      "test\n",
      "Epoch 30, Loss: 0.6931, RMSE: 3.6514, Recall@10: 0.0028, Precision@10: 0.0057\n",
      "test\n",
      "Epoch 31, Loss: 0.6931, RMSE: 3.6514, Recall@10: 0.0028, Precision@10: 0.0057\n",
      "test\n",
      "Epoch 32, Loss: 0.6931, RMSE: 3.6514, Recall@10: 0.0028, Precision@10: 0.0057\n",
      "test\n",
      "Epoch 33, Loss: 0.6931, RMSE: 3.6514, Recall@10: 0.0029, Precision@10: 0.0059\n",
      "test\n",
      "Epoch 34, Loss: 0.6931, RMSE: 3.6514, Recall@10: 0.0029, Precision@10: 0.0059\n",
      "test\n",
      "Epoch 35, Loss: 0.6931, RMSE: 3.6514, Recall@10: 0.0029, Precision@10: 0.0059\n",
      "test\n",
      "Epoch 36, Loss: 0.6931, RMSE: 3.6514, Recall@10: 0.0029, Precision@10: 0.0059\n",
      "test\n",
      "Epoch 37, Loss: 0.6931, RMSE: 3.6514, Recall@10: 0.0030, Precision@10: 0.0061\n",
      "test\n",
      "Epoch 38, Loss: 0.6931, RMSE: 3.6514, Recall@10: 0.0030, Precision@10: 0.0061\n",
      "test\n",
      "Epoch 39, Loss: 0.6931, RMSE: 3.6514, Recall@10: 0.0030, Precision@10: 0.0061\n",
      "test\n",
      "Epoch 40, Loss: 0.6931, RMSE: 3.6514, Recall@10: 0.0030, Precision@10: 0.0061\n",
      "test\n",
      "Epoch 41, Loss: 0.6931, RMSE: 3.6514, Recall@10: 0.0030, Precision@10: 0.0061\n",
      "test\n",
      "Epoch 42, Loss: 0.6931, RMSE: 3.6514, Recall@10: 0.0030, Precision@10: 0.0061\n",
      "test\n",
      "Epoch 43, Loss: 0.6931, RMSE: 3.6514, Recall@10: 0.0030, Precision@10: 0.0061\n",
      "test\n",
      "Epoch 44, Loss: 0.6931, RMSE: 3.6514, Recall@10: 0.0030, Precision@10: 0.0061\n",
      "test\n",
      "Epoch 45, Loss: 0.6931, RMSE: 3.6514, Recall@10: 0.0030, Precision@10: 0.0061\n",
      "test\n",
      "Epoch 46, Loss: 0.6931, RMSE: 3.6514, Recall@10: 0.0030, Precision@10: 0.0061\n",
      "test\n",
      "Epoch 47, Loss: 0.6931, RMSE: 3.6514, Recall@10: 0.0030, Precision@10: 0.0061\n",
      "Early stopping triggered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-141-416316b66e6f>:29: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(save_file))\n"
     ]
    }
   ],
   "source": [
    "train_and_test(baseline_model, optimizer, scheduler, 'best_model_baseline.pt')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
